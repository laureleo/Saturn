{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argus\n",
    "\n",
    "Scope:\n",
    "* Sweden:\n",
    "* Scandinavia:\n",
    "* Europe:\n",
    "* World\n",
    "\n",
    "Scrape the main news for each country.\n",
    "\n",
    "Do I need a manual approach for each newspaper? Tiresome. Let's try to automate things.\n",
    "Grab the text element with the largest font on the main page?\n",
    "\n",
    "Grab the elements, search for h1...h6, pick the first largest one (and the subtext?)?\n",
    "\n",
    "No, font size is better.\n",
    "\n",
    "## Links\n",
    "https://en.wikipedia.org/wiki/List_of_newspapers_in_Sweden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE\n",
    "https://www.svd.se/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "Each scraper will have:\n",
    "* URL\n",
    "* Source Country\n",
    "* Source Language\n",
    "* Source Newspaper\n",
    "*\n",
    "* Scrape_function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spirit: a database of information needed to instantiate an \"eye\"\n",
    "corpus: a class that uses a row of information from \"spirit\" to create an eye.\n",
    "mind: A superclass that manifests all the eyes in the database and translates it into a target language.\n",
    "memory: A database of past scrape results \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pycountry\n",
    "from googletrans import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<googletrans.models.Translated at 0x7f94e22f1210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "translator.translate(\"Der Himmel ist blau und ich mag Bananen\", dest='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Auto): Sweden: (Auto): aftonbladet\n",
      "RIGHT NOW: National team player dead\n",
      "▸ Second death in three weeks in the same club\n",
      "\n",
      "(Auto): Sweden: (Auto): svd\n",
      "Brexit announcement: Will continue to negotiate\n",
      "Discussions will continue despite the deadline passed: \"Responsible to make an effort.\"\n",
      "\n",
      "(Auto): Sweden: (Auto): gp\n",
      "Woman charged after knife attack at pharmacy at Östra Hospital\n",
      "Plaintiff: \"She looks very aggressive and rushes towards me and stabs me\".\n",
      "\n",
      "(Auto): Sweden: (Auto): dn\n",
      "New study investigates whether pressure chambers can help\n",
      "This weekend, the first covid patient was discharged from Karolinska University Hospital who has received the treatment.\n",
      "\n",
      "(Auto): Sweden: (Auto): expressen\n",
      "New record for corona patients\n",
      "DIRECT REPORT: 72 hospitalized in Jönköping: \"Near that we need help\"\n",
      "\n",
      "(Auto): Denmark: (Auto): https://politiken\n",
      "Will we reach the Danish climate goal? See the curve that shows how it goes\n",
      "Professor of Economics: \"I have tried to read that agreement 14 times, but it is quite unclear to me what it is that they have actually agreed\" 299 researchers in appeal to the Folketing: Denmark should introduce a climate tax now\n",
      "\n",
      "(Auto): Germany: (Auto): spiegel\n",
      "Marketplace\n",
      "DISPLAY\n",
      "\n",
      "(Auto): France: (Auto): lemonde\n",
      "Services\n",
      "Service: vocational training Discover our distance learning courses Learn to code online Take your skills assessment online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class mind_of_argus:\n",
    "    \"\"\"\n",
    "    The Mind of Argus processes what all eyes see...\n",
    "    This class takes in a destination language and a list of eyes.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, target_lang = 'en'):\n",
    "        self.target_lang = target_lang\n",
    "        self.translator = Translator()\n",
    "        \n",
    "        \n",
    "\n",
    "    def communicate(self, url):\n",
    "        eye = eye_of_argus(url)\n",
    "        header = eye.perspective['header']\n",
    "        excerpt = eye.perspective['excerpt']\n",
    "        \n",
    "        print(f\"{eye.country}: {eye.newspaper}\")\n",
    "\n",
    "        try:\n",
    "            trans_header = self.translator.translate(header, dest = self.target_lang)\n",
    "            trans_excerpt = self.translator.translate(excerpt, dest = self.target_lang)\n",
    "            print(trans_header.text)\n",
    "            print(trans_excerpt.text)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(header)\n",
    "            print(excerpt)\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        \n",
    "a = mind_of_argus()\n",
    "\n",
    "\n",
    "\n",
    "places = [\n",
    "'https://www.aftonbladet.se/',\n",
    "'https://www.svd.se/',\n",
    "'https://www.gp.se/',\n",
    "'https://www.dn.se/',\n",
    "'https://www.expressen.se/',\n",
    "'https://politiken.dk/',\n",
    "'https://www.spiegel.de/',\n",
    "'https://www.lemonde.fr/'\n",
    "         \n",
    "]\n",
    "m = mind_of_argus()\n",
    "for p in places:\n",
    "    m.communicate(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Auto): Sweden: (Auto): aftonbladet\n",
      "'NoneType' object has no attribute 'group'\n",
      "JUST NU: Landslagsspelare död\n",
      "▸ Andra dödsfallet på tre veckor i samma klubb\n",
      "\n",
      "(Auto): Sweden: (Auto): svd\n",
      "'NoneType' object has no attribute 'group'\n",
      "Brexitbeskedet: Ska fortsätta förhandla\n",
      "Diskussionerna ska fortsätta trots passerad deadline: ”Ansvarsfullt att anstränga sig.”\n",
      "\n",
      "(Auto): Sweden: (Auto): gp\n",
      "'NoneType' object has no attribute 'group'\n",
      "Kvinna åtalas efter knivattack på apotek vid Östra sjukhuset\n",
      "Målsäganden: ”Hon ser väldigt aggressiv ut och rusar fram mot mig och hugger mig”.\n",
      "\n",
      "(Auto): Sweden: (Auto): dn\n",
      "'NoneType' object has no attribute 'group'\n",
      "Tidsfrist för brexitsamtal skjuts upp – igen\n",
      "EU-kommissionens ordförande Ursula von der Leyen: ”Ansvarsfullt att göra det lilla extra.”\n",
      "\n",
      "(Auto): Sweden: (Auto): expressen\n",
      "'NoneType' object has no attribute 'group'\n",
      "Toppnotering för patienter med covid-19 i Jönköping\n",
      "DIREKTRAPPORT: 72 inlagda: ”Nära att vi behöver ta hjälp”\n",
      "\n",
      "(Auto): Denmark: (Auto): https://politiken\n",
      "'NoneType' object has no attribute 'group'\n",
      "Når vi det danske klimamål? Se kurven, der viser, hvordan det går\n",
      "Økonomi­professor: »Jeg har prøvet at læse den aftale 14 gange, men det står mig ret uklart, hvad det egentlig er, de har aftalt« 299 forskere i opråb til Folketinget: Danmark bør indføre en klimaskat nu\n",
      "\n",
      "(Auto): Germany: (Auto): spiegel\n",
      "'NoneType' object has no attribute 'group'\n",
      "Marktplatz\n",
      "ANZEIGE\n",
      "\n",
      "(Auto): France: (Auto): lemonde\n",
      "'NoneType' object has no attribute 'group'\n",
      "Services\n",
      "Service : codes promo Code promo Cdiscount : -10€ sur votre commande -10% pour les étudiants avec ASOS Code promo Sephora : -20% sur le site\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eye_of_argus():\n",
    "    \"\"\"\n",
    "    The Eyes of Argus sees all.\n",
    "    \n",
    "    The basic scraper class for this project.\n",
    "    Each instance of an eye should at least provide an url, with which the eye will do it's best to get relevant content.\n",
    "    Specifying the type of scraper, newspaper name etc make the returned information more relevant\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, url, country = 'auto', newspaper = 'auto', language = 'auto', notes = 'None'):\n",
    "        self.url = url\n",
    "        self.country = country\n",
    "        self.newspaper = newspaper\n",
    "        self.language = language\n",
    "        self.notes = notes\n",
    "        self.perspective = self.get_perspective()\n",
    "        self.format_perspective()\n",
    "        \n",
    "        if self.newspaper == 'auto':\n",
    "            self.newspaper =  '(Auto): ' + self.url.split(sep = '.')[-2]\n",
    "        \n",
    "        if self.country =='auto':\n",
    "            domain = self.url.split(sep = '.')[-1][:-1] \n",
    "            try:\n",
    "                country = pycountry.countries.get(alpha_2=domain).name\n",
    "                self.country = '(Auto): ' + country\n",
    "            except:\n",
    "                self.country = \"Failed to infer\"\n",
    "            \n",
    "    def get_soup(self):\n",
    "        html = requests.get(self.url)\n",
    "        soup = BeautifulSoup(html.content)\n",
    "        return soup\n",
    "\n",
    "\n",
    "    def get_perspective(self):\n",
    "        content = self.get_soup()\n",
    "\n",
    "        response = {\n",
    "        'header' : \"Not Found\",\n",
    "        'excerpt' : \"Not Found\"\n",
    "        }\n",
    "        \n",
    "        if self.url not in manual.keys():\n",
    "            response = self.naive_scrape(content, response)\n",
    "        \n",
    "        else:\n",
    "            eye = manual[self.url]\n",
    "            response = self.smart_scraper(content, response, eye)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def format_perspective(self):\n",
    "        #Make sure the content is a string. If not, assume it is a bs4 tag and extract the text element\n",
    "        for key in self.perspective:\n",
    "            \n",
    "            if self.perspective[key] == '\\n':\n",
    "                self.perspective[key] = \"Not Found\"\n",
    "                \n",
    "            if type(self.perspective[key]) != type('string'):\n",
    "                self.perspective[key] = self.perspective[key].text\n",
    "            \n",
    "            # Remove leading and trailing whitespace\n",
    "            split = self.perspective[key].split()\n",
    "            join = ' '.join(split)\n",
    "            self.perspective[key] = join\n",
    "            \n",
    "    def naive_scrape(self, content, response):\n",
    "        for head in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            rubric = content.find(head)\n",
    "            if rubric != None:\n",
    "                response['header'] = rubric\n",
    "                response['excerpt'] = rubric.findNext()\n",
    "                if response['excerpt'] == '\\n':\n",
    "                    response['excerpt'] = rubric.findNext().findNext()\n",
    "                    \n",
    "        return response\n",
    "    \n",
    "    def smart_scraper(self, content, response, specific_scraper):\n",
    "        \"\"\"\n",
    "        The smart_scraper is a higher-order function\n",
    "        It relies on the existence of functions with a specific format.\n",
    "        That is, a function that retures the header element of content when 'header' is specified'\n",
    "        and the excerpt element when 'excerpt is specified'\n",
    "        \"\"\"\n",
    "    \n",
    "        header = specific_scraper(content, 'header')\n",
    "        if header != None:\n",
    "            response['header'] = header\n",
    "            excerpt = specific_scraper(content, 'excerpt')\n",
    "            if excerpt != None:\n",
    "                response['excerpt'] =  excerpt\n",
    "        return response\n",
    "   \n",
    "    def describe(self, level = 0):\n",
    "        auto = ''\n",
    "        if self.url not in manual.keys():\n",
    "            auto = '(Auto):'\n",
    "\n",
    "        if level == 0:\n",
    "\n",
    "            print(f\"\"\"\n",
    "            SOURCE: {self.newspaper}\n",
    "            Header: {auto} {self.perspective['header']}\n",
    "\n",
    "            Excerpt: {auto} {self.perspective['excerpt']}\n",
    "            \"\"\")\n",
    "        else:\n",
    "            \n",
    "            print(f\"\"\"\n",
    "            url: {self.url}\n",
    "            country: {self.country}\n",
    "            newspaper: {self.newspaper}\n",
    "            language: {self.language}\n",
    "            notes: {self.notes}\n",
    "\n",
    "            Header:{auto} {self.perspective['header']}\n",
    "\n",
    "            Excerpt: {auto} {self.perspective['excerpt']}\n",
    "            \"\"\")\n",
    "            \n",
    "manual = {\n",
    "    'https://www.aftonbladet.se/' : swe_aft,\n",
    "    'https://www.svd.se/' : swe_svd,\n",
    "    'https://www.gp.se/': swe_gp,\n",
    "    'https://www.dn.se/': swe_dn,\n",
    "    'https://www.expressen.se/': swe_exp,\n",
    "    'https://politiken.dk/': dk_pol\n",
    "      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GERMANY\n",
    "\n",
    "# DENMARK\n",
    "def dk_pol(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find('h2', attrs={'class': 'article-intro__title headline headline--xxxlarge'})\n",
    "    if item == 'excerpt':\n",
    "        return content.find('h2', attrs={'class': 'article-intro__title headline headline--xxxlarge'}).parent.find('ul', attrs={'class': 'article-intro__related'})\n",
    "\n",
    "# SWEDEN\n",
    "\n",
    "def swe_exp(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find('div', attrs={'class': 'teaser'}).find('h2')\n",
    "    if item == 'excerpt':\n",
    "        return content.find('div', attrs={'class': 'teaser'}).find('h2').next_sibling\n",
    "\n",
    "def swe_dn(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find('div', attrs= {'class': 'teaser-package__content'}).find('h1')\n",
    "    if item == 'excerpt':\n",
    "        return content.find('div', attrs= {'class': 'teaser-package__content'}).find('h1').next_sibling.next_sibling\n",
    "\n",
    "def swe_gp(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find(\"div\",  attrs = {'class': 'c-teaser__content'}).find(\"h2\", attrs = {'class': 'c-teaser__title'})\n",
    "    if item == 'excerpt':\n",
    "        return content.find(\"div\", attrs = {'class': 'c-teaser__summery'})\n",
    "    \n",
    "def swe_aft(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find('h3')\n",
    "    if item == 'excerpt':\n",
    "        return content.find('h3').next_sibling\n",
    "    \n",
    "def swe_svd(content, item):\n",
    "    if item == 'header':\n",
    "        return content.find('h2')\n",
    "    if item == 'excerpt':\n",
    "        return content.find('h2').next_sibling.next_sibling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
